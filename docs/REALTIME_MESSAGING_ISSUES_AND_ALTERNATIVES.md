# 即时通讯：消息实时性现状、Socket.io 弊端与替代方案

本文档讨论当前基于 Socket.io 的即时通讯在**消息实时性**、**心跳/在线状态**及**加密传输**方面存在的问题，以及可行的替代或补充方案。

---

## 一、当前架构简述

- **通信基础**：Socket.io（ASGI 模式，挂载在 FastAPI 下）
- **认证**：连接时 `auth: { token: JWT }`，服务端 `decode_token` 校验后 `enter_room(sid, "user_{user_id}")`
- **心跳**：服务端 `ping_interval=25s` / `ping_timeout=60s`；应用层另有自定义 `ping`/`pong` 事件 + 后台任务每 30s 检查 `last_heartbeat`，超 90s 主动断开
- **传输**：生产环境依赖反向代理（Nginx 等）提供 WSS；连接 URL 由客户端配置（可 HTTP/HTTPS）

---

## 二、消息实时性方面存在的问题

### 2.1 已修复与仍存在的点

| 问题 | 状态 | 说明 |
|------|------|------|
| 重连后收不到 message | ✅ 已修复 | `message` 已收拢到 Provider 的 `messageStream`，重连后新 socket 会重新注册 |
| 仅聊天页订阅、会话列表不实时 | ✅ 已优化 | 会话列表已消费 `messageStream`，实时更新最后一条与未读数 |
| 弱网/切网导致断线 | ⚠️ 固有 | WebSocket 在移动网络切换、后台被系统回收时易断，依赖重连；重连间隔与策略影响“假离线”时长 |
| 消息顺序与去重 | ⚠️ 需保证 | 若重连后拉历史 + 实时流同时存在，需按 `id`/`created_at` 去重排序，避免重复或乱序 |

### 2.2 实时性瓶颈归纳

1. **连接生命周期**：App 退后台或锁屏后，系统常回收 WebSocket，导致“在线”实际已断，但服务端要等心跳超时（90s）才判定离线，这段时间内推送的在线状态不准确。
2. **单通道**：所有事件（消息、已读、通话邀请、在线状态）共用一个 Socket.io 连接，无优先级与背压控制，极端情况下可能互相影响。
3. **无离线/弱网兜底**：断线期间的消息依赖重连后的拉历史或推送；若重连慢或失败，用户会感觉“不实时”。

---

## 三、以 Socket.io 为通信基础的心跳与在线状态弊端

### 3.1 心跳机制现状

- **Engine.IO 层**：`ping_interval=25`、`ping_timeout=60`（秒），由 Socket.io 库自动发 ping/pong，用于维持连接。
- **应用层**：自定义 `ping` 事件（客户端可发）、服务端更新 `last_heartbeat` 并回 `pong`；后台任务每 30s 扫描，超过 `HEARTBEAT_TIMEOUT=90s` 则 `disconnect(sid)`。

### 3.2 弊端分析

| 弊端 | 说明 |
|------|------|
| **双重心跳、语义重叠** | Engine.IO 已有 ping/pong，应用层再维护一套 `ping`/`last_heartbeat`，逻辑重复；若客户端未发应用层 `ping`（例如只依赖库自带），服务端 `last_heartbeat` 可能不更新，导致被误杀。 |
| **在线状态滞后** | 断线后服务端要等约 90s 才断开并更新在线状态，列表里会长时间显示“在线”；移动端退后台几秒内连接就断，但“离线”要 90s 后才体现。 |
| **心跳与功耗/流量** | 25s 一次心跳在移动端可接受，但在弱网下容易因偶尔丢包被判定超时断开，重连又带来额外流量与电量消耗。 |
| **跨设备/多端** | 当前以 `user_id` 为维度维护连接，同一用户多设备会多连接；心跳超时按连接粒度踢掉，若只踢一个 sid，其他连接仍在，在线状态容易不一致。 |

### 3.3 改进方向（在保留 Socket.io 的前提下）

- **统一心跳语义**：要么只依赖 Engine.IO 的 ping/pong 做存活判断（并据此在服务端维护“最后活动时间”），要么只用应用层 ping/pong，避免两套逻辑不一致。
- **缩短超时与检查间隔**：在可接受误杀率下，适当减小 `HEARTBEAT_TIMEOUT` 和检查间隔，让“离线”更快反映；或对移动端单独使用更短的超时。
- **连接与在线状态解耦**：在线状态可结合“最后收到应用层心跳/消息的时间” + 短 TTL 缓存，而不是仅依赖“当前是否在 connected_users 里”。

---

## 四、加密与传输安全方面的问题

### 4.1 当前状况

- **链路加密**：依赖部署层 TLS（HTTPS/WSS）。若生产环境使用 Nginx 等终止 TLS 并反向代理到后端，则浏览器/App 到 Nginx 段是加密的，Nginx 到后端多为内网明文（或本机）。
- **认证**：连接时携带 JWT（`auth.token`），JWT 本身不加密 payload，仅签名防篡改；敏感字段若放在 payload 里，中间人不可改但可读。
- **消息体**：业务消息（如 chat message、call_invitation）在应用层**未做端到端加密**，即服务端和任意能拿到 DB 或抓包内网的人都能明文看到内容。

### 4.2 存在的问题

| 问题 | 说明 |
|------|------|
| **无端到端加密（E2EE）** | 消息明文落库、明文经服务端转发，无法满足“仅收发双方可见”的强隐私需求。 |
| **JWT 在连接时一次性使用** | 建连后若不刷新 token，长连接持有旧 token 直到断开；若 token 被撤销（登出、改密），需依赖心跳/重连或服务端主动踢线才能生效。 |
| **传输层依赖部署** | 是否 WSS 完全由部署决定；若误配成 WS 或 HTTP，则无加密。 |

### 4.3 可选改进

- **保证全链路 TLS**：生产环境统一使用 WSS，并在客户端写死或配置为 `wss://`，避免降级到 WS。
- **应用层可选 E2EE**：对“私密会话”在客户端对消息体加密后再发送，服务端只存密文；密钥交换与身份绑定需单独设计（如 Signal 协议简化版或库），与当前 Socket.io 可并存（Socket.io 只负责传输密文）。
- **Token 刷新与踢线**：支持在连接期间用 refresh token 换新 JWT，并在服务端维护“已撤销 token 黑名单”或“每用户最新 token 版本”，在心跳或关键操作时校验，过期/被撤销则断开。

---

## 五、替代/补充方案概览

### 5.1 继续以 Socket.io 为主（推荐短期）

- **做法**：保持现有架构，补齐/统一心跳、在线状态与重连策略；必要时增加“断线期间”的轮询或 SSE 拉取，作为实时通道的兜底。
- **优点**：改造成本小，与现有 FastAPI/Socket.io 服务端兼容。
- **缺点**：仍受 WebSocket 在移动端易断、单通道无优先级等限制。

### 5.2 原生 WebSocket（替换 Socket.io）

- **做法**：服务端用 FastAPI 的 `WebSocket` 或 Starlette WebSocket 自实现协议：鉴权、心跳、房间/用户路由、消息格式（如 JSON 类型 + payload）。
- **优点**：无 Socket.io 依赖，协议完全可控；可精简心跳与在线逻辑，便于与 E2EE 或自定义二进制格式结合。
- **缺点**：需自行实现重连、重试、房间管理、多端推送等，开发和测试成本高。

### 5.3 MQTT

- **做法**：引入 MQTT Broker（如 EMQX），客户端与后端通过 MQTT 订阅/发布；即时消息通过 topic（如 `user/{id}/inbox`）推送。
- **优点**：适合弱网、低功耗；QoS、持久化、离线消息由 Broker 提供。
- **缺点**：需维护 Broker；与现有 HTTP/Socket.io 并存时要统一鉴权与用户标识；移动端需接入 MQTT 客户端库。

### 5.4 XMPP

- **做法**：使用 XMPP 服务器（如 Ejabberd、Openfire）做消息与在线状态，客户端通过 XMPP 协议连接。
- **优点**：协议成熟、生态完善；在线状态、多端、历史消息有现成语义。
- **缺点**：与当前 REST + Socket.io 架构差异大，迁移成本高；若只做“聊天+在线”，可能过重。

### 5.5 推送 + 短轮询/长轮询（作补充）

- **做法**：不替代 Socket.io，而是当检测到 Socket 长时间未连或多次重连失败时，降级为定时轮询 `/chat/messages` 或 SSE；重要通知（如来电、@）用 FCM/APNs 唤醒 App 再建连或拉取。
- **优点**：实时性依赖 Socket，推送与轮询兜底，兼容弱网与后台限制。
- **缺点**：轮询有延迟与额外请求；推送需配置 FCM/APNs。

### 5.6 方案对比小结

| 方案 | 实时性 | 在线/心跳 | 加密与扩展 | 改造成本 | 建议 |
|------|--------|-----------|------------|----------|------|
| Socket.io 优化 | 中～高 | 需统一心跳与超时 | 依赖 TLS；E2EE 可叠加 | 低 | **短期首选** |
| 原生 WebSocket | 高 | 自控 | 易接 E2EE/自定义格式 | 高 | 中长期可选 |
| MQTT | 高（弱网友好） | Broker 支持 | 依赖 TLS + 应用层 | 中高 | 弱网/物联网场景 |
| XMPP | 高 | 协议内置 | 依赖 TLS + 应用层 | 高 | 全协议迁移时考虑 |
| 推送+轮询（补充） | 中 | 不解决 | 同现有 | 低 | **建议作为兜底** |

---

## 六、建议的落地顺序（已落实部分）

1. **短期（保持 Socket.io）** — 已做：
   - **统一心跳**：已移除应用层 ping/pong 与超时任务，仅使用 Engine.IO 的 `ping_interval=20`、`ping_timeout=40`，离线判定约 60s。
   - **轮询兜底**：聊天页在 Socket 断开时每 25s 轮询一次 `_loadMessages()`，连接恢复后停止。
   - **视频邀请可见性**：进入聊天页后 2s 做一次延迟刷新；主叫通过 `call_invitation_sent` 写入系统消息；已读标记使用 `safeInt`。
   - 待做：确认生产环境全量 WSS；会话列表消费 `messageStream` 以实时更新最后一条/未读。

2. **中期（按需增强）**
   - 会话列表、未读数等也消费 `messageStream` / `messageReadStream`，减少仅靠轮询接口的延迟。
   - 若业务需要“仅双方可见”，再设计端到端加密（密钥交换 + 消息体加密），Socket.io 仅传密文。

3. **长期（视需求再评估）**
   - 若移动端断线率、弱网体验仍不理想，可评估引入 MQTT 或原生 WebSocket 作为新通道，与现有接口并存、逐步迁移。

---

## 七、参考文献与相关文档

- 项目内：`docs/APP_REALTIME_MESSAGE_AND_ALTERNATIVES.md`（重连与订阅修复）
- Socket.io：<https://socket.io/docs/v4/server-options/>
- Engine.IO：ping_interval / ping_timeout 与连接保活

以上为对当前即时通讯在实时性、心跳在线及加密方面的问题与替代方案的讨论摘要，便于后续按优先级落地改进。
